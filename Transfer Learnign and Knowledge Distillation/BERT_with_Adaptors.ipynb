{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_with_Adaptors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6b8cdd5eaf445a3a16d7fe1bc7f997d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c110dd9e77046a59ead5fcc9d621426",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c911f9de38e468aab09be6cb7a91c90",
              "IPY_MODEL_09535d9fde774819aeebc63c8020e01f"
            ]
          }
        },
        "0c110dd9e77046a59ead5fcc9d621426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c911f9de38e468aab09be6cb7a91c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d7f6802c9dd4dc5a016089cc189efd2",
            "_dom_classes": [],
            "description": "Epoch [1/3]: [307/307] 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 307,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 307,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_865ab04bba394830be48eb834bbde50b"
          }
        },
        "09535d9fde774819aeebc63c8020e01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78667ba26458453180add81916df599d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=1.04 [00:14&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0039c89b11545d9b10da002a073c71a"
          }
        },
        "2d7f6802c9dd4dc5a016089cc189efd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "865ab04bba394830be48eb834bbde50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78667ba26458453180add81916df599d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0039c89b11545d9b10da002a073c71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f00d6a38cee41189b05f450e0c25995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20bf5f9810ed474d8af7aaaa14064251",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e25ea880dd947c08be33403caa185f6",
              "IPY_MODEL_6a8e9dd61ccc4af598b936ac1e7e3744"
            ]
          }
        },
        "20bf5f9810ed474d8af7aaaa14064251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e25ea880dd947c08be33403caa185f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3bc3f522669c4e53baafdda4d545d8f9",
            "_dom_classes": [],
            "description": "Epoch [2/3]: [307/307] 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 307,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 307,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49334da70ded45e8944c7cca044d363f"
          }
        },
        "6a8e9dd61ccc4af598b936ac1e7e3744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9697d3ed693044cdb7df671360a39fb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0.623 [00:14&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6efd3fa3eb564bab838d69b7c8ddb194"
          }
        },
        "3bc3f522669c4e53baafdda4d545d8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49334da70ded45e8944c7cca044d363f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9697d3ed693044cdb7df671360a39fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6efd3fa3eb564bab838d69b7c8ddb194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "994d94f2c1aa49aa90b977b27d40a0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_507bf5af4c7247869efc9b6c0432b228",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f67234e44bd0463e9b10dfba2bca0749",
              "IPY_MODEL_27d7ffe6d2c74f598fb4eb6dd6f3f7c9"
            ]
          }
        },
        "507bf5af4c7247869efc9b6c0432b228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f67234e44bd0463e9b10dfba2bca0749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05c805a9779643449287dcfa8bd16896",
            "_dom_classes": [],
            "description": "Epoch [3/3]: [307/307] 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 307,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 307,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e77df191df74f3395fbc59341a063fa"
          }
        },
        "27d7ffe6d2c74f598fb4eb6dd6f3f7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75ac898f65a84516b39bd334daacacfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", loss=0.464 [00:14&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13409ebdf3944aaa8c73ccc397a13460"
          }
        },
        "05c805a9779643449287dcfa8bd16896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e77df191df74f3395fbc59341a063fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ac898f65a84516b39bd334daacacfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13409ebdf3944aaa8c73ccc397a13460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgQHWoSe4TY5",
        "colab_type": "text"
      },
      "source": [
        "# **Pretrained BERT with adaptors (additional bottlenecks inside the Transformer Block ![alt text](https://drive.google.com/uc?id=1ZeVWel3DetaY3Y9YUc3BczS-Q4FP0Pfj))**\n",
        "For more detail, please refer to the original paper @ \"Parameter-Efficient Transfer Learning for BERT\" Houlsby et al., 2019\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XBDLhv-8M0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "13ff6891-6d14-4fa7-8197-25cbd558196a"
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-ignite ipdb"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25hCollecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/55/41e8a995876fd2ade29bdba0c3efefa38e7d605cb353c70f3173c04928b5/pytorch_ignite-0.3.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.7MB/s \n",
            "\u001b[?25hCollecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/bb/a3e1a441719ebd75c6dac8170d3ddba884b7ee8a5c0f9aefa7297386627a/ipdb-0.13.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.1.3)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.1.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.2-cp36-none-any.whl size=10522 sha256=3cfc15906e2f7dddcebca50341e891ad10474fbc42c009b5fa6385a92058064a\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/c2/15/793365e3c9318c46ba914263740d90f1fe67f544b979141ce4\n",
            "Successfully built ipdb\n",
            "Installing collected packages: pytorch-pretrained-bert, pytorch-ignite, ipdb\n",
            "Successfully installed ipdb-0.13.2 pytorch-ignite-0.3.0 pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMec4Mt16dt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Transformer Blocks\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_dim, num_embeddings, num_max_positions, num_heads, num_layers, dropout, causal):\n",
        "        super().__init__()\n",
        "        self.causal = causal\n",
        "        self.tokens_embeddings = nn.Embedding(num_embeddings, embed_dim)\n",
        "        self.position_embeddings = nn.Embedding(num_max_positions, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.attentions, self.feed_forwards = nn.ModuleList(), nn.ModuleList()\n",
        "        self.layer_norms_1, self.layer_norms_2 = nn.ModuleList(), nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.attentions.append(nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout))\n",
        "            self.feed_forwards.append(nn.Sequential(nn.Linear(embed_dim, hidden_dim),\n",
        "                                                    nn.ReLU(),\n",
        "                                                    nn.Linear(hidden_dim, embed_dim)))\n",
        "            self.layer_norms_1.append(nn.LayerNorm(embed_dim, eps=1e-12))\n",
        "            self.layer_norms_2.append(nn.LayerNorm(embed_dim, eps=1e-12))\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        \"\"\" x has shape [seq length, batch], padding_mask has shape [batch, seq length] \"\"\"\n",
        "        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n",
        "        h = self.tokens_embeddings(x)\n",
        "        h = h + self.position_embeddings(positions).expand_as(h)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        attn_mask = None\n",
        "        if self.causal:\n",
        "            attn_mask = torch.full((len(x), len(x)), -float('Inf'), device=h.device, dtype=h.dtype)\n",
        "            attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        for layer_norm_1, attention, layer_norm_2, feed_forward in zip(self.layer_norms_1, self.attentions,\n",
        "                                                                       self.layer_norms_2, self.feed_forwards):\n",
        "            h = layer_norm_1(h)\n",
        "            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n",
        "            x = self.dropout(x)\n",
        "            h = x + h\n",
        "\n",
        "            h = layer_norm_2(h)\n",
        "            x = feed_forward(h)\n",
        "            x = self.dropout(x)\n",
        "            h = x + h\n",
        "            print(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvWmuQVU6lCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Transformer with Adapter\n",
        "\n",
        "class TransformerWithAdapters(Transformer): # Inherit from the pretrained Transformer Block  to have all the modules\n",
        "    def __init__(self, adapters_dim, embed_dim, hidden_dim, num_embeddings, num_max_positions,\n",
        "                 num_heads, num_layers, dropout, causal):\n",
        "        \"\"\" Transformer with adapters (small bottleneck layers) \"\"\"\n",
        "        super().__init__(embed_dim, hidden_dim, num_embeddings, num_max_positions, num_heads, num_layers,\n",
        "                         dropout, causal)\n",
        "        self.adapters_1 = nn.ModuleList()\n",
        "        self.adapters_2 = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "          \n",
        "            self.adapters_1.append(nn.Sequential(nn.Linear(embed_dim, adapters_dim),\n",
        "                                                 nn.ReLU(),\n",
        "                                                 nn.Linear(adapters_dim, embed_dim))) ## First adapter: bottleneck layers with 2 linear layers and a ReLU(dim is usually small\n",
        "                                                                                        #32, 64, 128, 256\n",
        "            \n",
        "            self.adapters_2.append(nn.Sequential(nn.Linear(embed_dim, adapters_dim), ## Second adapter\n",
        "                                                 nn.ReLU(),\n",
        "                                                 nn.Linear(adapters_dim, embed_dim)))\n",
        "\n",
        "    def forward(self, x, padding_mask=None):\n",
        "        \"\"\" x has shape [seq length, batch], padding_mask has shape [batch, seq length] \"\"\"\n",
        "        positions = torch.arange(len(x), device=x.device).unsqueeze(-1)\n",
        "        h = self.tokens_embeddings(x)\n",
        "        h = h + self.position_embeddings(positions).expand_as(h)  \n",
        "        h = self.dropout(h)\n",
        "\n",
        "        attn_mask = None\n",
        "        if self.causal:\n",
        "            attn_mask = torch.full((len(x), len(x)), -float('Inf'), device=h.device, dtype=h.dtype)\n",
        "            attn_mask = torch.triu(attn_mask, diagonal=1)\n",
        "\n",
        "        for (layer_norm_1, attention, adapter_1, layer_norm_2, feed_forward, adapter_2)\\\n",
        "                          in zip(self.layer_norms_1, self.attentions,    self.adapters_1,\n",
        "                                 self.layer_norms_2, self.feed_forwards, self.adapters_2):\n",
        "            h = layer_norm_1(h)\n",
        "            x, _ = attention(h, h, h, attn_mask=attn_mask, need_weights=False, key_padding_mask=padding_mask)\n",
        "            x = self.dropout(x)\n",
        "            \n",
        "            x = adapter_1(x) + x  # Add an adapter with a skip-connection after attention module\n",
        "            \n",
        "            h = x + h\n",
        "\n",
        "            h = layer_norm_2(h)\n",
        "            x = feed_forward(h)\n",
        "            x = self.dropout(x)\n",
        "            \n",
        "            x = adapter_2(x) + x  # Add an adapter with a skip-connection after feed-forward module\n",
        "            \n",
        "            h = x + h\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09JY1wx766Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Adding Classification layer on top of the blocks\n",
        "\n",
        "\n",
        "\n",
        "class TransformerWithClfHeadAndAdapters(nn.Module):\n",
        "    def __init__(self, config, fine_tuning_config):\n",
        "        \"\"\" Transformer with a classification head and adapters. \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = fine_tuning_config\n",
        "        self.transformer = TransformerWithAdapters(fine_tuning_config.adapters_dim, config.embed_dim, config.hidden_dim,\n",
        "                                                   config.num_embeddings, config.num_max_positions, config.num_heads,\n",
        "                                                   config.num_layers, fine_tuning_config.dropout, causal=not config.mlm)\n",
        "\n",
        "        self.classification_head = nn.Linear(config.embed_dim, fine_tuning_config.num_classes)\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding, nn.LayerNorm)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, (nn.Linear, nn.LayerNorm)) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, clf_tokens_mask, lm_labels=None, clf_labels=None, padding_mask=None):\n",
        "        hidden_states = self.transformer(x, padding_mask) #return hidden_states with dimensions of (embed_dim, seq_length, batch)\n",
        "\n",
        "        clf_tokens_states = (hidden_states * clf_tokens_mask.unsqueeze(-1).float()).sum(dim=0)\n",
        "        clf_logits = self.classification_head(clf_tokens_states)\n",
        "\n",
        "        if clf_labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(clf_logits.view(-1, clf_logits.size(-1)), clf_labels.view(-1))\n",
        "            return clf_logits, loss\n",
        "\n",
        "        return clf_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrbAR4tY8JQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4381d3e-d778-4192-d62c-21f6561ffd3a"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, cached_path\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 213450/213450 [00:00<00:00, 2355786.33B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHQ_4Zf075YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Configuration\n",
        "from collections import namedtuple\n",
        "\n",
        "Config = namedtuple('Config',\n",
        "  field_names=\"embed_dim, hidden_dim, num_max_positions, num_embeddings      , num_heads, num_layers,\" \n",
        "              \"dropout, initializer_range, batch_size, lr, max_norm, n_epochs, n_warmup,\"\n",
        "              \"mlm, gradient_accumulation_steps, device, log_dir, dataset_cache\")\n",
        "args = Config( 410      , 2100      , 256              , len(tokenizer.vocab), 10       , 16        ,\n",
        "               0.1    , 0.02             , 16        , 2.5e-4, 1.0 , 50     , 1000    ,\n",
        "               False, 4, \"cuda\" if torch.cuda.is_available() else \"cpu\", \"./\"   , \"./dataset_cache.bin\")\n",
        "\n",
        "AdaptationConfig = namedtuple('AdaptationConfig',\n",
        "  field_names=\"adapters_dim, num_classes, dropout, initializer_range, batch_size, lr, max_norm, n_epochs,\"\n",
        "              \"n_warmup, valid_set_prop, gradient_accumulation_steps, device,\"\n",
        "              \"log_dir, dataset_cache\")\n",
        "adapt_args = AdaptationConfig(\n",
        "               32         , 6          , 0.1    , 0.02             , 16        , 6.5e-4, 1.0   , 3,\n",
        "               10      , 0.1           , 1, \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "               \"./\"   , \"./dataset_cache.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFPoq_Ku8Eyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f4d112ae-5e72-4000-adb0-159fe91fd20a"
      },
      "source": [
        "# If you have pretrained a model in the first section, you can use its weigths\n",
        "# state_dict = model.state_dict()\n",
        "\n",
        "# Otherwise, just load pretrained model weigths (and reload the training config as well)\n",
        "state_dict = torch.load(cached_path(\"https://s3.amazonaws.com/models.huggingface.co/\"\n",
        "                                    \"naacl-2019-tutorial/model_checkpoint.pth\"), map_location='cpu')\n",
        "args = torch.load(cached_path(\"https://s3.amazonaws.com/models.huggingface.co/\"\n",
        "                                    \"naacl-2019-tutorial/model_training_args.bin\"))\n",
        "\n",
        "adaptation_model = TransformerWithClfHeadAndAdapters(config=args, fine_tuning_config=adapt_args)\n",
        "adaptation_model.to(adapt_args.device)\n",
        "\n",
        "incompatible_keys = adaptation_model.load_state_dict(state_dict, strict=False)\n",
        "print(f\"Parameters discarded from the pretrained model: {incompatible_keys.unexpected_keys}\")\n",
        "print(f\"Parameters added in the adaptation model: {incompatible_keys.missing_keys}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 201626725/201626725 [00:04<00:00, 43081899.88B/s]\n",
            "100%|██████████| 837/837 [00:00<00:00, 580941.99B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters discarded from the pretrained model: ['lm_head.weight']\n",
            "Parameters added in the adaptation model: ['transformer.adapters_1.0.0.weight', 'transformer.adapters_1.0.0.bias', 'transformer.adapters_1.0.2.weight', 'transformer.adapters_1.0.2.bias', 'transformer.adapters_1.1.0.weight', 'transformer.adapters_1.1.0.bias', 'transformer.adapters_1.1.2.weight', 'transformer.adapters_1.1.2.bias', 'transformer.adapters_1.2.0.weight', 'transformer.adapters_1.2.0.bias', 'transformer.adapters_1.2.2.weight', 'transformer.adapters_1.2.2.bias', 'transformer.adapters_1.3.0.weight', 'transformer.adapters_1.3.0.bias', 'transformer.adapters_1.3.2.weight', 'transformer.adapters_1.3.2.bias', 'transformer.adapters_1.4.0.weight', 'transformer.adapters_1.4.0.bias', 'transformer.adapters_1.4.2.weight', 'transformer.adapters_1.4.2.bias', 'transformer.adapters_1.5.0.weight', 'transformer.adapters_1.5.0.bias', 'transformer.adapters_1.5.2.weight', 'transformer.adapters_1.5.2.bias', 'transformer.adapters_1.6.0.weight', 'transformer.adapters_1.6.0.bias', 'transformer.adapters_1.6.2.weight', 'transformer.adapters_1.6.2.bias', 'transformer.adapters_1.7.0.weight', 'transformer.adapters_1.7.0.bias', 'transformer.adapters_1.7.2.weight', 'transformer.adapters_1.7.2.bias', 'transformer.adapters_1.8.0.weight', 'transformer.adapters_1.8.0.bias', 'transformer.adapters_1.8.2.weight', 'transformer.adapters_1.8.2.bias', 'transformer.adapters_1.9.0.weight', 'transformer.adapters_1.9.0.bias', 'transformer.adapters_1.9.2.weight', 'transformer.adapters_1.9.2.bias', 'transformer.adapters_1.10.0.weight', 'transformer.adapters_1.10.0.bias', 'transformer.adapters_1.10.2.weight', 'transformer.adapters_1.10.2.bias', 'transformer.adapters_1.11.0.weight', 'transformer.adapters_1.11.0.bias', 'transformer.adapters_1.11.2.weight', 'transformer.adapters_1.11.2.bias', 'transformer.adapters_1.12.0.weight', 'transformer.adapters_1.12.0.bias', 'transformer.adapters_1.12.2.weight', 'transformer.adapters_1.12.2.bias', 'transformer.adapters_1.13.0.weight', 'transformer.adapters_1.13.0.bias', 'transformer.adapters_1.13.2.weight', 'transformer.adapters_1.13.2.bias', 'transformer.adapters_1.14.0.weight', 'transformer.adapters_1.14.0.bias', 'transformer.adapters_1.14.2.weight', 'transformer.adapters_1.14.2.bias', 'transformer.adapters_1.15.0.weight', 'transformer.adapters_1.15.0.bias', 'transformer.adapters_1.15.2.weight', 'transformer.adapters_1.15.2.bias', 'transformer.adapters_2.0.0.weight', 'transformer.adapters_2.0.0.bias', 'transformer.adapters_2.0.2.weight', 'transformer.adapters_2.0.2.bias', 'transformer.adapters_2.1.0.weight', 'transformer.adapters_2.1.0.bias', 'transformer.adapters_2.1.2.weight', 'transformer.adapters_2.1.2.bias', 'transformer.adapters_2.2.0.weight', 'transformer.adapters_2.2.0.bias', 'transformer.adapters_2.2.2.weight', 'transformer.adapters_2.2.2.bias', 'transformer.adapters_2.3.0.weight', 'transformer.adapters_2.3.0.bias', 'transformer.adapters_2.3.2.weight', 'transformer.adapters_2.3.2.bias', 'transformer.adapters_2.4.0.weight', 'transformer.adapters_2.4.0.bias', 'transformer.adapters_2.4.2.weight', 'transformer.adapters_2.4.2.bias', 'transformer.adapters_2.5.0.weight', 'transformer.adapters_2.5.0.bias', 'transformer.adapters_2.5.2.weight', 'transformer.adapters_2.5.2.bias', 'transformer.adapters_2.6.0.weight', 'transformer.adapters_2.6.0.bias', 'transformer.adapters_2.6.2.weight', 'transformer.adapters_2.6.2.bias', 'transformer.adapters_2.7.0.weight', 'transformer.adapters_2.7.0.bias', 'transformer.adapters_2.7.2.weight', 'transformer.adapters_2.7.2.bias', 'transformer.adapters_2.8.0.weight', 'transformer.adapters_2.8.0.bias', 'transformer.adapters_2.8.2.weight', 'transformer.adapters_2.8.2.bias', 'transformer.adapters_2.9.0.weight', 'transformer.adapters_2.9.0.bias', 'transformer.adapters_2.9.2.weight', 'transformer.adapters_2.9.2.bias', 'transformer.adapters_2.10.0.weight', 'transformer.adapters_2.10.0.bias', 'transformer.adapters_2.10.2.weight', 'transformer.adapters_2.10.2.bias', 'transformer.adapters_2.11.0.weight', 'transformer.adapters_2.11.0.bias', 'transformer.adapters_2.11.2.weight', 'transformer.adapters_2.11.2.bias', 'transformer.adapters_2.12.0.weight', 'transformer.adapters_2.12.0.bias', 'transformer.adapters_2.12.2.weight', 'transformer.adapters_2.12.2.bias', 'transformer.adapters_2.13.0.weight', 'transformer.adapters_2.13.0.bias', 'transformer.adapters_2.13.2.weight', 'transformer.adapters_2.13.2.bias', 'transformer.adapters_2.14.0.weight', 'transformer.adapters_2.14.0.bias', 'transformer.adapters_2.14.2.weight', 'transformer.adapters_2.14.2.bias', 'transformer.adapters_2.15.0.weight', 'transformer.adapters_2.15.0.bias', 'transformer.adapters_2.15.2.weight', 'transformer.adapters_2.15.2.bias', 'classification_head.weight', 'classification_head.bias']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGezWZle8m0U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12c13e9b-6bd8-4081-8a67-7f69104fc085"
      },
      "source": [
        "## Only train embeddings, classification head, adapter 1, and adapter 2, other weights are not being trained\n",
        "for name, param in adaptation_model.named_parameters():\n",
        "    if 'embedding' not in name and 'classification' not in name and 'adapter_1' not in name and 'adapter_2' not in name:\n",
        "        param.detach_()\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "full_parameters = sum(p.numel() for p in adaptation_model.parameters())\n",
        "trained_parameters = sum(p.numel() for p in adaptation_model.parameters() if p.requires_grad )\n",
        "\n",
        "print(f\"We will train {trained_parameters:3e} parameters out of {full_parameters:3e},\"\n",
        "      f\" i.e. {100 * trained_parameters/full_parameters:.2f}%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We will train 1.199579e+07 parameters out of 5.125265e+07, i.e. 23.41%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RpfGAUj_v7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.metrics import RunningAverage, Accuracy\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.contrib.handlers import CosineAnnealingScheduler, PiecewiseLinear, create_lr_scheduler_with_warmup, ProgressBar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0WeDpCNAYJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVZw4TIg-FdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3d6f384-f8b1-4a4b-e791-cc085c9e542a"
      },
      "source": [
        "import random\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset_file = cached_path(\"https://s3.amazonaws.com/datasets.huggingface.co/trec/\"\n",
        "                           \"trec-tokenized-bert.bin\")\n",
        "datasets = torch.load(dataset_file)\n",
        "\n",
        "for split_name in ['train', 'test']:\n",
        "\n",
        "    # Trim the samples to the transformer's input length minus 1 & add a classification token\n",
        "    datasets[split_name] = [x[:args.num_max_positions-1] + [tokenizer.vocab['[CLS]']]\n",
        "                            for x in datasets[split_name]]\n",
        "\n",
        "    # Pad the dataset to max length\n",
        "    padding_length = max(len(x) for x in datasets[split_name])\n",
        "    datasets[split_name] = [x + [tokenizer.vocab['[PAD]']] * (padding_length - len(x))\n",
        "                            for x in datasets[split_name]]\n",
        "\n",
        "    # Convert to torch.Tensor and gather inputs and labels\n",
        "    tensor = torch.tensor(datasets[split_name], dtype=torch.long)\n",
        "    labels = torch.tensor(datasets[split_name + '_labels'], dtype=torch.long)\n",
        "    datasets[split_name] = TensorDataset(tensor, labels)\n",
        "\n",
        "# Create a validation dataset from a fraction of the training dataset\n",
        "valid_size = int(adapt_args.valid_set_prop * len(datasets['train']))\n",
        "train_size = len(datasets['train']) - valid_size\n",
        "valid_dataset, train_dataset = random_split(datasets['train'], [valid_size, train_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=adapt_args.batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=adapt_args.batch_size, shuffle=False)\n",
        "test_loader = DataLoader(datasets['test'], batch_size=adapt_args.batch_size, shuffle=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250835/250835 [00:00<00:00, 2186940.95B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxut2n2s9XKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5dda1278-a9fb-4462-85bf-ed7064506591"
      },
      "source": [
        "## training loop\n",
        "optimizer = torch.optim.Adam(adaptation_model.parameters(), lr=adapt_args.lr)\n",
        "\n",
        "##training function and trainer\n",
        "def update(engine, batch):\n",
        "    adaptation_model.train()\n",
        "    batch, labels = (t.to(adapt_args.device) for t in batch)\n",
        "    inputs = batch.transpose(0,1).contiguous() #to shape [seq_length, batch]\n",
        "\n",
        "    _, loss = adaptation_model(inputs, clf_tokens_mask=(inputs == tokenizer.vocab['[CLS]']), clf_labels=labels,\n",
        "                                                        padding_mask = (batch ==tokenizer.vocab['[PAD]']))\n",
        "    \n",
        "    loss = loss/adapt_args.gradient_accumulation_steps\n",
        "    loss.backward()\n",
        "    if engine.state.iteration % adapt_args.gradient_accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return loss.item()\n",
        "trainer = Engine(update)\n",
        "\n",
        "\n",
        "def inference(engine, batch):\n",
        "    adaptation_model.eval()\n",
        "    with torch.no_grad():\n",
        "        batch, labels = (t.to(adapt_args.device) for t in batch)\n",
        "        inputs = batch.transpose(0, 1).contiguous()  # to shape [seq length, batch]\n",
        "        clf_logits = adaptation_model(inputs, clf_tokens_mask=(inputs == tokenizer.vocab['[CLS]']),\n",
        "                                      padding_mask=(batch == tokenizer.vocab['[PAD]']))\n",
        "    return clf_logits, labels\n",
        "evaluator = Engine(inference)\n",
        "\n",
        "# Attache metric to evaluator & evaluation to trainer: evaluate on valid set after each epoch\n",
        "Accuracy().attach(evaluator, \"accuracy\")\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(engine):\n",
        "    evaluator.run(valid_loader)\n",
        "    print(f\"Validation Epoch: {engine.state.epoch} Error rate: {100*(1 - evaluator.state.metrics['accuracy'])}\")\n",
        "\n",
        "# Learning rate schedule: linearly warm-up to lr and then to zero\n",
        "scheduler = PiecewiseLinear(optimizer, 'lr', [(0, 0.0), (adapt_args.n_warmup, adapt_args.lr),\n",
        "                                              (len(train_loader)*adapt_args.n_epochs, 0.0)])\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "\n",
        "# Add progressbar with loss\n",
        "RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n",
        "ProgressBar(persist=True).attach(trainer, metric_names=['loss'])\n",
        "\n",
        "# Save checkpoints and finetuning config\n",
        "checkpoint_handler = ModelCheckpoint(adapt_args.log_dir, 'finetuning_checkpoint', save_interval=1, require_empty=False)\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {'mymodel': adaptation_model})\n",
        "torch.save(args, os.path.join(adapt_args.log_dir, 'fine_tuning_args.bin'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ignite/handlers/checkpoint.py:369: UserWarning: Argument save_interval is deprecated and should be None. Please, use events filtering instead, e.g. Events.ITERATION_STARTED(every=1000)\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi4Ra1Hg9acL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "d6b8cdd5eaf445a3a16d7fe1bc7f997d",
            "0c110dd9e77046a59ead5fcc9d621426",
            "0c911f9de38e468aab09be6cb7a91c90",
            "09535d9fde774819aeebc63c8020e01f",
            "2d7f6802c9dd4dc5a016089cc189efd2",
            "865ab04bba394830be48eb834bbde50b",
            "78667ba26458453180add81916df599d",
            "b0039c89b11545d9b10da002a073c71a",
            "5f00d6a38cee41189b05f450e0c25995",
            "20bf5f9810ed474d8af7aaaa14064251",
            "9e25ea880dd947c08be33403caa185f6",
            "6a8e9dd61ccc4af598b936ac1e7e3744",
            "3bc3f522669c4e53baafdda4d545d8f9",
            "49334da70ded45e8944c7cca044d363f",
            "9697d3ed693044cdb7df671360a39fb0",
            "6efd3fa3eb564bab838d69b7c8ddb194",
            "994d94f2c1aa49aa90b977b27d40a0ad",
            "507bf5af4c7247869efc9b6c0432b228",
            "f67234e44bd0463e9b10dfba2bca0749",
            "27d7ffe6d2c74f598fb4eb6dd6f3f7c9",
            "05c805a9779643449287dcfa8bd16896",
            "2e77df191df74f3395fbc59341a063fa",
            "75ac898f65a84516b39bd334daacacfd",
            "13409ebdf3944aaa8c73ccc397a13460"
          ]
        },
        "outputId": "5a9131e6-f3e4-4c7c-967b-b72ea4443b5f"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=adapt_args.n_epochs)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6b8cdd5eaf445a3a16d7fe1bc7f997d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=307), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Epoch: 1 Error rate: 29.357798165137616\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f00d6a38cee41189b05f450e0c25995",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=307), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Epoch: 2 Error rate: 21.65137614678899\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "994d94f2c1aa49aa90b977b27d40a0ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=307), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Epoch: 3 Error rate: 18.899082568807334\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 921\n",
              "\tepoch: 3\n",
              "\tepoch_length: 307\n",
              "\tmax_epochs: 3\n",
              "\toutput: 0.2108326107263565\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: 12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBju1CaSAdBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca797f9d-46b0-4817-d8d9-01958226bf06"
      },
      "source": [
        "evaluator.run(test_loader)\n",
        "print(f\"Test Results - Error rate: {100*(1.00 - evaluator.state.metrics['accuracy']):.3f}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Results - Error rate: 15.200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuHAooX_AvmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}