{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Covid_19_Semantic_Search.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jna8ttzPGgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNJKyl2VPZR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### read dataframe after preprocessing\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/clean_df.csv', index_col = 0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_kZPJUUQdm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### We are gonna use the abstract as summarization of papers, thus we need to further remove the NaN\n",
        "df = df.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apdSu4PIRBCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av25tFX9RBoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "df['body_text'] = df['body_text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
        "df['abstract'] = df['abstract'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8JDYf-cRi55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lower_case(input_str):\n",
        "    input_str = input_str.lower()\n",
        "    return input_str\n",
        "\n",
        "df['body_text'] = df['body_text'].apply(lambda x: lower_case(x))\n",
        "df['abstract'] = df['abstract'].apply(lambda x: lower_case(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZRfi79DRn8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmLe0pt2R3pD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/semantic_covid.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUCbRz7cR_GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_covid_test = pd.read_csv(\"/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/semantic_covid.csv\")\n",
        "text = df_covid_test.drop([\"authors\", \"journal\", \"Unnamed: 0\"], axis=1)\n",
        "text.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofuJ41ISSVxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_dict = text.to_dict()\n",
        "len_text = len(text_dict[\"paper_id\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ie-FRQSgCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "paper_id_list  = []\n",
        "body_text_list = []\n",
        "\n",
        "title_list = []\n",
        "abstract_list = []\n",
        "abstract_summary_list = []\n",
        "for i in tqdm(range(0,len_text)):\n",
        "  paper_id = text_dict[\"paper_id\"][i]\n",
        "  body_text = text_dict[\"body_text\"][i].split(\"\\n\")\n",
        "  title = text_dict[\"title\"][i]\n",
        "  abstract = text_dict[\"abstract\"][i]\n",
        "  abstract_summary = text_dict[\"abstract_summary\"][i]\n",
        "  for b in body_text:\n",
        "    paper_id_list.append(paper_id)\n",
        "    body_text_list.append(b)\n",
        "    title_list.append(title)\n",
        "    abstract_list.append(abstract)\n",
        "    abstract_summary_list.append(abstract_summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Tsq6PvSjOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sentences = pd.DataFrame({\"paper_id\":paper_id_list},index=body_text_list)\n",
        "df_sentences.to_csv(\"/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/semantic_sentences.csv\")\n",
        "df_sentences.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or5j9OdpSpGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sentences = pd.DataFrame({\"paper_id\":paper_id_list,\"title\":title_list,\"abstract\":abstract_list,\"abstract_summary\":abstract_summary_list},index=body_text_list)\n",
        "df_sentences.to_csv(\"/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/covid_sentences_Full.csv\")\n",
        "df_sentences.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNswNomeS3fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sentences = df_sentences[\"paper_id\"].to_dict()\n",
        "df_sentences_list = list(df_sentences.keys())\n",
        "len(df_sentences_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzgy-9HpTPec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(df_sentences.keys())[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJz0CrSJTSlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sentences_list = [str(d) for d in tqdm(df_sentences_list)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA_SywkhTVe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/covid_sentences_Full.csv\", index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1D7L8w3TZpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
        "\"\"\"\n",
        "This is a simple application for sentence embeddings: semantic search\n",
        "We have a corpus with various sentences. Then, for a given query sentence,\n",
        "we want to find the most similar sentence in this corpus.\n",
        "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
        "\"\"\"\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import scipy.spatial\n",
        "import pickle as pkl\n",
        "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = df_sentences_list\n",
        "corpus_embeddings = embedder.encode(corpus,show_progress_bar=True)\n",
        "with open(\"/content/drive/My Drive/BertSentenceSimilarity/Pickles/corpus_embeddings.pkl\" , \"rb\") as file_:\n",
        "  corpus_embeddings = pkl.load(file_)\n",
        "\n",
        "# Query sentences:\n",
        "queries = ['What has been published about medical care?',\n",
        "           'Knowledge of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19, including, but not limited to, possible cardiomyopathy and cardiac arrest',\n",
        "           'Use of AI in real-time health care delivery to evaluate interventions, risk factors, and outcomes in a way that could not be done manually',\n",
        "           'Resources to support skilled nursing facilities and long term care facilities.',\n",
        "           'Mobilization of surge medical staff to address shortages in overwhelmed communities .',\n",
        "           'Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with/without other organ failure â€“ particularly for viral etiologies .']\n",
        "query_embeddings = embedder.encode(queries,show_progress_bar=True)\n",
        "\n",
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "closest_n = 5\n",
        "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "for query, query_embedding in zip(queries, query_embeddings):\n",
        "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "    print(\"\\n\\n=========================================================\")\n",
        "    print(\"==========================Query==============================\")\n",
        "    print(\"===\",query,\"=====\")\n",
        "    print(\"=========================================================\")\n",
        "\n",
        "\n",
        "    for idx, distance in results[0:closest_n]:\n",
        "        print(\"Score:   \", \"(Score: %.4f)\" % (1-distance) , \"\\n\" )\n",
        "        print(\"Paragraph:   \", corpus[idx].strip(), \"\\n\" )\n",
        "        row_dict = df.loc[df.index== corpus[idx]].to_dict()\n",
        "        print(\"paper_id:  \" , row_dict[\"paper_id\"][corpus[idx]] , \"\\n\")\n",
        "        print(\"Title:  \" , row_dict[\"title\"][corpus[idx]] , \"\\n\")\n",
        "        print(\"Abstract:  \" , row_dict[\"abstract\"][corpus[idx]] , \"\\n\")\n",
        "        print(\"Abstract_Summary:  \" , row_dict[\"abstract_summary\"][corpus[idx]] , \"\\n\")\n",
        "        print(\"-------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC9iD0W1Tmtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}