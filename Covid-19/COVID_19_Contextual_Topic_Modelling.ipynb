{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID_19_Contextual_Topic_Modelling.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "crhoqnalng6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RKvwe-nshJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Deep Learning Data/Covid-19 Text Mining/clean_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTWp3M-2n6EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzXSnLL4pRpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['processed_text'][:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4riWpakpWww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "def vectorizer(text, max_features):\n",
        "    \"\"\"Args:\n",
        "            -text: input text (assumed being cleaned)\n",
        "            -max_features: length of the extracted vector\"\"\"\n",
        "    vectorizer = TfidfVectorizer(max_features = max_features)\n",
        "    X = vectorizer.fit_transform(text)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR5vfQAQp6iI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = df['processed_text'].values\n",
        "X = vectorizer(text, 2 ** 9 ) ## transform text into Tfidf vectors of size (no_of_documents x 512)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2yb4yszqSUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###PCA and Clustering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMyJGbNZsH1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOcSNlSCsWDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_reduced= pca.fit_transform(X.toarray())\n",
        "X_reduced.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1q4LbdOCBMN",
        "colab_type": "text"
      },
      "source": [
        "So 341 PCAs can explain 95% variance in our dataset, that is significant reduction from 512 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9QougNNsWm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-CNxh02rPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 20\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "y_pred = kmeans.fit_predict(X_reduced)\n",
        "df['y'] = y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-nRsO3V3EWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(verbose=1, perplexity=100, random_state=42)\n",
        "X_embedded = tsne.fit_transform(X.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRptFQv3ORE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# sns settings\n",
        "sns.set(rc={'figure.figsize':(15,15)})\n",
        "\n",
        "# colors\n",
        "palette = sns.hls_palette(20, l=.4, s=.9)\n",
        "\n",
        "# plot\n",
        "sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\n",
        "plt.title('t-SNE with Kmeans Labels')\n",
        "plt.savefig(\"improved_cluster_tsne.png\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fExVuo1-CsQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8NcDRx-Z4g",
        "colab_type": "text"
      },
      "source": [
        "We can see some clusters but not very good at all\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZdBVH16AJFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## We will try to get title embedding using BERT\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es5dZDJmCpZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn9882bRDBop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B8h5DS4DD5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_example = df['title'][0]\n",
        "print(\"Original title: \", title_example)\n",
        "marked_text = \"[CLS]\" + title_example +\"[SEP]\"\n",
        "print(\"Title after added special tokens: \", marked_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfVfL4u4DL5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "print(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejm65lnzD7iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = df['title'][10]\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSNQxGJXEYgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_type_id =[]\n",
        "attention_mask = []\n",
        "for i in range(len(df['title'])):\n",
        "    idx = tokenizer.encode_plus(df['title'][i], add_special_tokens=True, max_length = 200, pad_to_max_length=True, \n",
        "                                      return_attention_mask = True, return_tensors = 'pt')\n",
        "    token_type_id.append(idx['token_type_ids'])\n",
        "    attention_mask.append(idx['attention_mask'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65kz0MGBFXxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(token_type_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4CyR7bcHnPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_tensor = torch.cat(token_type_id,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flndAAk8JKuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_tensor = torch.cat(attention_mask,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CILwh_ghMMYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "id_generator = Dataloader(id_tensor, batch_size = 32, num_workers = 1)\n",
        "attention_generator = Dataloader(id_tensor, batch_size = 32, num_workers = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5taZQE1JMpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##use pretrained bert as feature extractors\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n",
        "embeddings=[]\n",
        "for i, batch in enumerate(zip(id_generator, attention_generator), 0):\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = model(input_ids = batch[0], attention_masks = batch[1])\n",
        "        embeddings.append(encoded_layers)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__ikdIXfK429",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}