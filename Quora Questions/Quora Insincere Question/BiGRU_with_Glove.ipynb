{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiGRU with Glove.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgpp_hhyIVHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "69305562-d9cf-4509-9ddd-a3e51ea5e1fb"
      },
      "source": [
        "!unzip '/content/drive/My Drive/Deep Learning Data/Quora Insincere Question/quora-insincere-questions-classification.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Deep Learning Data/Quora Insincere Question/quora-insincere-questions-classification.zip\n",
            "  inflating: embeddings.zip          \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bLyNexLI8Jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "d8892620-b2d1-47e1-9a64-8d42613c5bc9"
      },
      "source": [
        "!unzip '/content/embeddings.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/embeddings.zip\n",
            "   creating: GoogleNews-vectors-negative300/\n",
            "   creating: glove.840B.300d/\n",
            "   creating: paragram_300_sl999/\n",
            "   creating: wiki-news-300d-1M/\n",
            "  inflating: glove.840B.300d/glove.840B.300d.txt  \n",
            "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
            "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
            "  inflating: paragram_300_sl999/README.txt  \n",
            "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhjKHrlsLCkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "19b1f7c2-4c67-4179-e336-04d6350137b9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import operator\n",
        "import re\n",
        "import gc\n",
        "import keras\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVCpJ-ILN6Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "df = pd.concat([train ,test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5N4avSOYGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "f3d95123-9146-4722-c4f0-1627d27a541d"
      },
      "source": [
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375801</th>\n",
              "      <td>ffff7fa746bd6d6197a9</td>\n",
              "      <td>How many countries listed in gold import in in...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375802</th>\n",
              "      <td>ffffa1be31c43046ab6b</td>\n",
              "      <td>Is there an alternative to dresses on formal p...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375803</th>\n",
              "      <td>ffffae173b6ca6bfa563</td>\n",
              "      <td>Where I can find best friendship quotes in Tel...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375804</th>\n",
              "      <td>ffffb1f7f1a008620287</td>\n",
              "      <td>What are the causes of refraction of light?</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375805</th>\n",
              "      <td>fffff85473f4699474b0</td>\n",
              "      <td>Climate change is a worrying topic. How much t...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1681928 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         qid  ... target\n",
              "0       00002165364db923c7e6  ...    0.0\n",
              "1       000032939017120e6e44  ...    0.0\n",
              "2       0000412ca6e4628ce2cf  ...    0.0\n",
              "3       000042bf85aa498cd78e  ...    0.0\n",
              "4       0000455dfa3e01eae3af  ...    0.0\n",
              "...                      ...  ...    ...\n",
              "375801  ffff7fa746bd6d6197a9  ...    NaN\n",
              "375802  ffffa1be31c43046ab6b  ...    NaN\n",
              "375803  ffffae173b6ca6bfa563  ...    NaN\n",
              "375804  ffffb1f7f1a008620287  ...    NaN\n",
              "375805  fffff85473f4699474b0  ...    NaN\n",
              "\n",
              "[1681928 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAWsBCk-Ojd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embed(file):\n",
        "    def get_coefs(word,*arr): \n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
        "    else:\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
        "        \n",
        "    return embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apBdUxK2POaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove = '/content/glove.840B.300d/glove.840B.300d.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iON32mF4PTw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d65dff5-1f44-4f1c-e943-e95a1c0b0209"
      },
      "source": [
        "print(\"Extracting GloVe embedding\")\n",
        "embed_glove = load_embed(glove)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting GloVe embedding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCk0P_OwPVUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5de7820-cf92-444f-ba91-02ff242fd71f"
      },
      "source": [
        "type(embed_glove)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsGGIoVLQGEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#helper function to create vocabulary\n",
        "def build_vocab(texts):\n",
        "    sentences = texts.apply(lambda x: x.split()).values\n",
        "    vocab = {}\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZYqn6TJQbCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## helper function to check vocabulary coverage\n",
        "def check_coverage(vocab, embeddings_index):\n",
        "    known_words = {}\n",
        "    unknown_words = {}\n",
        "    nb_known_words = 0\n",
        "    nb_unknown_words = 0\n",
        "    for word in vocab.keys():\n",
        "        try:\n",
        "            known_words[word] = embeddings_index[word]\n",
        "            nb_known_words += vocab[word]\n",
        "        except:\n",
        "            unknown_words[word] = vocab[word]\n",
        "            nb_unknown_words += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\n",
        "    print('Found embeddings for  {:.3%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
        "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return unknown_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKlfAjegQ6xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = build_vocab(df['question_text'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hexz8l9PR9Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8947c739-791b-49a4-bb2e-069a2592e94c"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab, embed_glove)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove : \n",
            "Found embeddings for 31.537% of vocab\n",
            "Found embeddings for  88.155% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA6YAyDaSDGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['lowered_question'] = df['question_text'].apply(lambda x: x.lower())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X44FHYYHSQXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_lower(embedding, vocab):\n",
        "    count = 0\n",
        "    for word in vocab:\n",
        "        if word in embedding and word.lower() not in embedding:  \n",
        "            embedding[word.lower()] = embedding[word]\n",
        "            count += 1\n",
        "    print(f\"Added {count} words to embedding\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDfW4A7RSS-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "e7d734bc-a438-4704-b9dd-7ebb2323d862"
      },
      "source": [
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab, embed_glove)\n",
        "add_lower(embed_glove, vocab)\n",
        "oov_glove = check_coverage(vocab, embed_glove)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove : \n",
            "Found embeddings for 31.537% of vocab\n",
            "Found embeddings for  88.155% of all text\n",
            "Added 17744 words to embedding\n",
            "Found embeddings for 31.820% of vocab\n",
            "Found embeddings for  88.171% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8c7dq5SUl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLVSgtpkSZyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def known_contractions(embed):\n",
        "    known = []\n",
        "    for contract in contraction_mapping:\n",
        "        if contract in embed:\n",
        "            known.append(contract)\n",
        "    return known"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtuZ8sjiSdi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00e99221-e8d0-486b-80f5-aefc2f71e6a8"
      },
      "source": [
        "print(\"   Glove :\")\n",
        "print(known_contractions(embed_glove))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Glove :\n",
            "[\"can't\", \"'cause\", \"didn't\", \"doesn't\", \"don't\", \"I'd\", \"I'll\", \"I'm\", \"I've\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"it's\", \"ma'am\", \"o'clock\", \"that's\", \"you'll\", \"you're\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lzGnNI1SfrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_contractions(text, mapping):\n",
        "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
        "    for s in specials:\n",
        "        text = text.replace(s, \"'\")\n",
        "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRz3CXFRSjjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['treated_question'] = df['lowered_question'].apply(lambda x: clean_contractions(x, contraction_mapping))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YBrPXYgSlIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "37121623-148e-4d17-e10e-1adb22c64064"
      },
      "source": [
        "vocab = build_vocab(df['treated_question'])\n",
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab, embed_glove)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove : \n",
            "Found embeddings for 29.302% of vocab\n",
            "Found embeddings for  88.570% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDBvCEP2SrIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrN9s4tCS9kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unknown_punct(embed, punct):\n",
        "    unknown = ''\n",
        "    for p in punct:\n",
        "        if p not in embed:\n",
        "            unknown += p\n",
        "            unknown += ' '\n",
        "    return unknown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWeqFLYVTANK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34a7b355-4d93-48e0-bed9-85c2f4075958"
      },
      "source": [
        "print(\"Glove :\")\n",
        "print(unknown_punct(embed_glove, punct))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove :\n",
            "“ ” ’ ∞ θ ÷ α • à − β ∅ ³ π ‘ ₹ ´ ° £ € × ™ √ ² — – \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nrR5bvuTB_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05q-a8BZTDwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct, mapping):\n",
        "    for p in mapping:\n",
        "        text = text.replace(p, mapping[p])\n",
        "    \n",
        "    for p in punct:\n",
        "        text = text.replace(p, f' {p} ')\n",
        "    \n",
        "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
        "    for s in specials:\n",
        "        text = text.replace(s, specials[s])\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrzLSFVYTGx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['treated_question'] = df['treated_question'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32yUAMHzTJjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a85c11d7-dfa6-4ddc-e73e-135f9a3a4cce"
      },
      "source": [
        "vocab = build_vocab(df['treated_question'])\n",
        "print(\"Glove : \")\n",
        "oov_glove = check_coverage(vocab, embed_glove)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove : \n",
            "Found embeddings for 66.961% of vocab\n",
            "Found embeddings for  99.580% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEudtOWHTWZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mNQZH-kTmWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_spelling(x, dic):\n",
        "    for word in dic.keys():\n",
        "        x = x.replace(word, dic[word])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z6D8Y1WTuDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['treated_question'] = df['treated_question'].apply(lambda x: correct_spelling(x, mispell_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWY2Fj6LTuna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "c9ba00f3-de29-4119-919f-b738b0ec9cef"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>lowered_question</th>\n",
              "      <th>treated_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>how did quebec nationalists see their province...</td>\n",
              "      <td>how did quebec nationalists see their province...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>do you have an adopted dog, how would you enco...</td>\n",
              "      <td>do you have an adopted dog  ,   how would you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>why does velocity affect time? does velocity a...</td>\n",
              "      <td>why does velocity affect time  ?   does veloci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>how did otto von guericke used the magdeburg h...</td>\n",
              "      <td>how did otto von guericke used the magdeburg h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>can i convert montra helicon d to a mountain b...</td>\n",
              "      <td>can i convert montra helicon d to a mountain b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ...                                   treated_question\n",
              "0  00002165364db923c7e6  ...  how did quebec nationalists see their province...\n",
              "1  000032939017120e6e44  ...  do you have an adopted dog  ,   how would you ...\n",
              "2  0000412ca6e4628ce2cf  ...  why does velocity affect time  ?   does veloci...\n",
              "3  000042bf85aa498cd78e  ...  how did otto von guericke used the magdeburg h...\n",
              "4  0000455dfa3e01eae3af  ...  can i convert montra helicon d to a mountain b...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5MqhJz_T0MH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lowering\n",
        "train['treated_question'] = train['question_text'].apply(lambda x: x.lower())\n",
        "# Contractions\n",
        "train['treated_question'] = train['treated_question'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
        "# Special characters\n",
        "train['treated_question'] = train['treated_question'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))\n",
        "# Spelling mistakes\n",
        "train['treated_question'] = train['treated_question'].apply(lambda x: correct_spelling(x, mispell_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmYbA3pjUrL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRqXHBmVU0ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_voc = 95000\n",
        "max_len = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7t6WP-pT8MV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_treated_data(X):\n",
        "    t = Tokenizer(num_words=len_voc, filters='')\n",
        "    t.fit_on_texts(X)\n",
        "    X = t.texts_to_sequences(X)\n",
        "    X = pad_sequences(X, maxlen=max_len)\n",
        "    return X, t.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdMKkq_vUk7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_treated, word_index_treated = make_treated_data(train['treated_question'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RllyuajaUmti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = train['target'].values\n",
        "X_t_train, X_t_val, y_train, y_test = train_test_split(X_treated, y, test_size=0.1, random_state=420)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGDBWQsKVA0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_embed_matrix(embeddings_index, word_index, len_voc):\n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "    word_index = word_index\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len_voc, embed_size))\n",
        "    \n",
        "    for word, i in word_index.items():\n",
        "        if i >= len_voc:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: \n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqPhgkLWVOSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a5f7ce59-7539-4dac-8b77-282866cae15a"
      },
      "source": [
        "embedding = make_embed_matrix(embed_glove, word_index_treated, len_voc)\n",
        "\n",
        "del word_index_treated\n",
        "gc.collect()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjWjf7IUY-I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index_treated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYApUqGVQSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import GRU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW5EstBiVho9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    \n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OrLiAWDVjuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Bidirectional, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Input, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwJb-UICVmjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
        "    inp    = Input(shape=(max_len,))\n",
        "    x      = Embedding(len_voc, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x      = Bidirectional(GRU(128, return_sequences=True))(x)\n",
        "    x      = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    avg_pl = GlobalAveragePooling1D()(x)\n",
        "    max_pl = GlobalMaxPooling1D()(x)\n",
        "    concat = concatenate([avg_pl, max_pl])\n",
        "    dense  = Dense(64, activation=\"relu\")(concat)\n",
        "    drop   = Dropout(0.1)(concat)\n",
        "    output = Dense(1, activation=\"sigmoid\")(concat)\n",
        "    \n",
        "    model  = Model(inputs=inp, outputs=output)\n",
        "    model.compile(loss=loss, optimizer=Adam(lr=0.0001), metrics=['accuracy', f1])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ot0AE1dVr_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= make_model(embedding)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9HAj7rcYqF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3846a6db-0275-4a7e-f5c8-414796665d0e"
      },
      "source": [
        "embedding.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvbkmXvUVtyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "93f61738-c595-4f82-d9b3-12bde6acdeb4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 60, 300)      28500000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 60, 256)      329472      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 60, 128)      123264      bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           global_average_pooling1d_2[0][0] \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            257         concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 28,952,993\n",
            "Trainable params: 452,993\n",
            "Non-trainable params: 28,500,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rpvpLu4WOgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ko3kwMWVpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoints = ModelCheckpoint('weights.hdf5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_f1', factor=0.1, patience=2, verbose=1, min_lr=0.000001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJkY8blQWZ28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 8\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH0Irbs9Wg_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "d825b593-cc9a-4db3-a973-ea097cce4302"
      },
      "source": [
        "history = model_treated.fit(X_t_train, y_train, batch_size=batch_size, epochs=epochs, \n",
        "                            validation_data=[X_t_val, y_test], callbacks=[checkpoints, reduce_lr])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/8\n",
            " 612864/1175509 [==============>...............] - ETA: 7:16 - loss: 0.1447 - accuracy: 0.9459 - f1: 0.3825"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-6e836dddf327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model_treated.fit(X_t_train, y_train, batch_size=batch_size, epochs=epochs, \n\u001b[0;32m----> 2\u001b[0;31m                             validation_data=[X_t_val, y_test], callbacks=[checkpoints, reduce_lr])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8d09jbbWnxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}